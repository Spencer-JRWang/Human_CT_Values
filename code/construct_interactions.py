import shap
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import combinations
import networkx as nx
import pandas as pd
from itertools import combinations

# The Features are generated by RFE model
feature_combinations = [
    ['L1', 'L4', 'L5', 'S1', 'L1-L2_3', 'L2-L3_2', 'L2-L3_6', 'L3-L4_2', 'L4-L5_1', 'L4-L5_3'],
    ['L1', 'L4', 'L1-L2_3', 'L2-L3_4', 'L2-L3_5', 'L3-L4_1', 'L4-L5_1', 'L5-S1_4'],
    ['L1', 'L2', 'L4', 'L5', 'L1-L2_3', 'L1-L2_4', 'L1-L2_6', 'L2-L3_3', 'L2-L3_5', 'L3-L4_5', 'L4-L5_1', 'L4-L5_3', 'L4-L5_4', 'L4-L5_5'],
    ['L3', 'L5', 'S1', 'L1-L2_1', 'L1-L2_6', 'L2-L3_3', 'L2-L3_6', 'L3-L4_2', 'L3-L4_3', 'L4-L5_2', 'L4-L5_3', 'L4-L5_4', 'L4-L5_5'],
    ['L1', 'L5', 'S1', 'L1-L2_5', 'L1-L2_6', 'L2-L3_1', 'L2-L3_2', 'L2-L3_3', 'L2-L3_6', 'L3-L4_1', 'L3-L4_6', 'L4-L5_1', 'L4-L5_3'],
    ['L1', 'L2', 'L5', 'S1', 'L1-L2_2', 'L1-L2_3', 'L1-L2_4', 'L1-L2_6', 'L2-L3_2', 'L2-L3_3', 'L2-L3_4', 'L3-L4_1', 'L3-L4_2', 'L3-L4_3', 'L3-L4_6', 'L4-L5_2', 'L4-L5_5', 'L5-S1_1', 'L5-S1_4']
]

df_all = pd.read_csv('data/Human_CT_Values.txt', sep='\t')
df_all['Gender'] = df_all['Gender'].astype('category')
category = ["A", "B", "C", "D"]
category = list(combinations(category, 2))

Interactions = []
# Create a figure and set up the 3x2 grid of subplots
fig, axs = plt.subplots(3, 2, figsize=(15, 22.5))
axs = axs.flatten()  # Flatten the 2D array of axes to easily index

# In all combinations
for i in range(len(category)):
    Cat_A = category[i][0]
    Cat_B = category[i][1]
    df = df_all[df_all['Disease'].isin([Cat_A, Cat_B])]
    X = df.drop("Disease", axis=1)
    X = X[feature_combinations[i]]
    y = df['Disease']
    X = X.reset_index(drop=True)
    y = y.reset_index(drop=True)
    shuffle_index = np.random.permutation(X.index)
    X = X.iloc[shuffle_index]
    y = y.iloc[shuffle_index]
    y = y.map({Cat_A: 0, Cat_B: 1})
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    d_train = lgb.Dataset(X_train, label=y_train)
    d_test = lgb.Dataset(X_test, label=y_test)
    params = {
        "max_bin": 512,
        "learning_rate": 0.05,
        "boosting_type": "gbdt",
        "objective": "binary",
        "metric": "binary_logloss",
        "num_leaves": 10,
        "verbose": -1,
        "boost_from_average": True,
        "early_stopping_rounds": 50,
        "verbose_eval": 1000
    }
    model = lgb.train(
        params,
        d_train,
        1000,
        valid_sets=[d_test],
    )
    shap_interaction_values = shap.TreeExplainer(model).shap_interaction_values(X)
    interaction_matrix = np.abs(shap_interaction_values).sum(0)
    for j in range(interaction_matrix.shape[0]):
        interaction_matrix[j, j] = 0
    inds = np.argsort(-interaction_matrix.sum(0))[:len(feature_combinations[i])]
    sorted_ia_matrix = interaction_matrix[inds, :][:, inds]
    
    # Plot each heatmap in the corresponding subplot
    ax = axs[i]
    sns.heatmap(sorted_ia_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar_kws={'label': 'Intensity'}, cbar=False, ax=ax)
    ax.set_xticklabels(
        X.columns[inds],
        rotation=45,
        horizontalalignment="right"
    )
    ax.set_yticklabels(
        X.columns[inds],
        rotation=45,
        horizontalalignment="right"
    )
    ax.set_title(f"{category[i][0]} vs {category[i][1]}")
    # Construct
    feature_names = X.columns[inds]
    # Create a network graph
    G = nx.Graph()
    # Add nodes with feature names
    for feature in feature_names:
        G.add_node(feature)
    # Add edges with weights from the interaction matrix
    for row in range(sorted_ia_matrix.shape[0]):
        for col in range(row + 1, sorted_ia_matrix.shape[1]):
            weight = sorted_ia_matrix[row, col]
            if weight > 1.5:
                G.add_edge(feature_names[row], feature_names[col])
    Interactions.append(G)
# Adjust layout to prevent overlap
plt.tight_layout()
# Save the combined figure
plt.savefig("../figure/CT/Interaction2/combined_interaction_heatmaps.pdf", bbox_inches='tight')
plt.close()
print("Combined heatmap figure saved to ../figure/CT/Interaction2/combined_interaction_heatmaps.pdf")


# Save network structure
Graph_BMI = nx.compose_all(Interactions)
isolated_nodes = list(nx.isolates(Graph_BMI))
Graph_BMI.remove_nodes_from(isolated_nodes)
nx.write_graphml(Graph_BMI, 'data/network.graphml')


# Simple Visulaize
plt.figure(figsize=(10, 10))
plt.tight_layout()
node_colors = []
node_sizes = []
for node in Graph_BMI.nodes:
    if node in ['L1', 'L2', 'L3', 'L4', 'L5', 'S1']:
        node_colors.append('#FABB6E')
        node_sizes.append(1300)
    else:
        node_colors.append('#92C2DD')
        node_sizes.append(1200)
pos = nx.spring_layout(Graph_BMI, k=3)
# Draw nodes and edges
nx.draw_networkx_nodes(Graph_BMI, pos, node_color=node_colors, node_size=node_sizes)
nx.draw_networkx_edges(Graph_BMI, pos, edge_color='gray', width=2)
nx.draw_networkx_labels(Graph_BMI, pos, font_size=9, font_family='sans-serif')
ax = plt.gca()
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
# Remove ticks
ax.xaxis.set_ticks([])
ax.yaxis.set_ticks([])
plt.savefig('figure/CT/Combined_BMI/Network.pdf')
plt.show()

# Adj map
adj_matrix = nx.to_numpy_matrix(Graph_BMI)
# 设置无连接的节点为白色，有连接的节点为蓝色
adj_matrix = np.where(adj_matrix > 0, 1, 0)
# 绘制邻接矩阵热图，添加灰色网格线
plt.figure(figsize=(10, 10))
sns.heatmap(adj_matrix, cmap=sns.color_palette(['white', '#1f77b4']), annot=False, cbar=False, square=True,
            xticklabels=Graph_BMI.nodes(), yticklabels=Graph_BMI.nodes(), linewidths=0.7, linecolor='gray')
plt.title('Adjacency Matrix Heatmap')
plt.tight_layout()
plt.savefig('figure/CT/Combined_BMI/Adj.pdf')
plt.show()


# Analyze Centrality
# Betweenness
betweenness = nx.betweenness_centrality(Graph_BMI)
# Closeness
closeness = nx.closeness_centrality(Graph_BMI)
# Degree
degree = dict(Graph_BMI.degree())
# Clustering Coefficient
clustering = nx.clustering(Graph_BMI)
betweenness_sorted = dict(sorted(betweenness.items(), key=lambda item: item[1], reverse=True))
closeness_sorted = dict(sorted(closeness.items(), key=lambda item: item[1], reverse=True))
degree_sorted = dict(sorted(degree.items(), key=lambda item: item[1], reverse=True))
clustering_sorted = dict(sorted(clustering.items(), key=lambda item: item[1], reverse=True))
plt.figure(figsize=(10, 10))
plt.subplot(2, 2, 1)
plt.bar(betweenness_sorted.keys(), betweenness_sorted.values(), color='skyblue')
plt.title('Betweenness Centrality')
plt.xticks(rotation=90)
plt.subplot(2, 2, 2)
plt.bar(closeness_sorted.keys(), closeness_sorted.values(), color='lightgreen')
plt.title('Closeness Centrality')
plt.xticks(rotation=90)
plt.subplot(2, 2, 3)
plt.bar(degree_sorted.keys(), degree_sorted.values(), color='salmon')
plt.title('Degree')
plt.xticks(rotation=90)
plt.subplot(2, 2, 4)
plt.bar(clustering_sorted.keys(), clustering_sorted.values(), color='#FABB6E')
plt.title('Clustering Coefficient')
plt.xticks(rotation=90)
plt.tight_layout()
plt.savefig('../figure/CT/Combined_BMI/Centrality.pdf')
plt.show()
plt.close()